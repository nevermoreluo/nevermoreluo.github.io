{"posts":[{"title":"Intel VTune Profiler 性能分析","text":"Intel VTune ProfilerIntel VTune Profiler 以下简称Vtune,是intel推出的一款用于应用性能分析的一款软件工具集，是的区别于普通的分析软件，它其实一系列分析工具的集合。支持windows，linux，macos等系统，以及c/c++, Java, go, .Net, python等多种语言。其内部还有多种分析维度 安装按照官方文档安装即可以下简述 ubuntu安装过程下载对应的离线安装shell脚本，（当然也可以按apt安装），wget https://registrationcenter-download.intel.com/akdlm/irc_nas/18267/l_oneapi_vtune_p_2021.8.0.533_offline.sh 此处部分同学有科学上网软件的话，可能浏览器下载比wget快。 下载完成后执行sudo bash l_oneapi_vtune_p_2021.8.0.533_offline.sh即开始安装 安装完成后,还需要根据文档执行source /opt/intel/oneapi/vtune/latest/env/vars.sh,即可通过vtune-gui打开vtune了， 最好将该命令写入 ~/.bashrc内 Hotspots是用于分析cpu占用时间最多的调用，可以通过各种图形化gui的分析过滤方式查看cpu比较高的时刻函数占用情况。 依旧是经典的旁路采样分析模式的采样数据， 配置完应用程序以及环境变量后，当你按下执行后，程序会开始启动，按下stop则开始分析采样数据生成各种图表。 其中的Bottom-up, Top-down Tree, Flame Graph 图表,其实都是同一组数据在不同纬度以及不同图表展示下的结果，因此可以统一对下方条件过滤处，进行时间，线程，动态库等条件过滤达到自己想查看的某些时刻或者某些部分的cpu占用比，这个很实用。 由于图表会涉及很多业务数据 因此只将外部启动的主程序图表做一个展示， 外部启动程序其实会根据配置载入不同的动态库实现不同功能因此主要都是系统库dlopen的占用,暂时不准备对这部分做优化，而且此处占用也只会在服务器起来的时候占用一次，因此本次暂时不优化该部分。 我们甚至可以通过双击对应想要查看的函数，获得函数每行语句的cpu时间占比。","link":"/2023/09/14/Intel-VTune-Profiler-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"},{"title":"Linux service register script","text":"前言工作中存在一些功能需要注册为服务，保证开机自启以及自动重启业务。其实本质上就是注册一个service unit, 但是很多同学都没搞过。为了减少一些同学的使用成本，就给了个简单脚本按步骤执行。 Show me the code123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102#!/bin/bashset -e;CURRENT_SCRIPT_DIR=$(dirname &quot;$(readlink -f &quot;$0&quot;)&quot;)# 默认来说该注册脚本和程序一起放程序根目录那么CURRENT_SCRIPT_DIR就是项目根目录PROJECT_DIR=$CURRENT_SCRIPT_DIR# 设定服务名称 后续systemctl stop $SERVICE_NAME 用SERVICE_NAME=# 设定服务运行程序# EXEC_FILE=$PROJECT_DIR/$SERVICE_NAME# 运行程序 这里可以带参数# 例如 START_CMD=$EXEC_FILE -f $PROJECT_DIR/config.json# 可能会有启动参数 没有就直接填执行程序START_CMD=$EXEC_FILEHAS_START_CMD_ARGS=0# 参数缺省时，用户交互手动输入if [ -z &quot;$SERVICE_NAME&quot; ]; then read -p &quot;Please set an service name: &quot; SERVICE_NAME if [ -z &quot;$SERVICE_NAME&quot; ]; then echo &quot;We can not register service with empty name, bye!!!&quot;; exit 1; fifiif [ -z &quot;$EXEC_FILE&quot; ]; then read -p &quot;Please set full path for project dir: &quot; PROJECT_DIR if [ -z &quot;$PROJECT_DIR&quot; ]; then PROJECT_DIR=$CURRENT_SCRIPT_DIR fi read -p &quot;Please set full path for exec file: &quot; EXEC_FILE fiif [[ $HAS_START_CMD_ARGS -ne 0 &amp;&amp; -z $START_CMD ]]; then read -p &quot;Please set start cmd: &quot; START_CMDelse START_CMD=$EXEC_FILEfiSYSTEM_CONF=/usr/lib/systemd/system/$SERVICE_NAME.serviceecho &quot;SERVICE_NAME: $SERVICE_NAME&quot;echo &quot;PROJECT_DIR: $PROJECT_DIR&quot;echo &quot;EXEC_FILE: $EXEC_FILE&quot;echo &quot;START_CMD: $START_CMD&quot;echo &quot;Start install $SERVICE_NAME...&quot;cd $PROJECT_DIRif [ -e $SYSTEM_CONF ]; then read -p &quot;Warning!!! $SERVICE_NAME is already installed. skip install and setup $SERVICE_NAME? (y/n) &quot; choice case &quot;$choice&quot; in y|Y ) echo &quot;Continuing...&quot; ;; n|N ) echo &quot;Exiting...&quot; exit 0 ;; * ) echo &quot;Invalid choice. Exiting...&quot; exit 1 ;; esacelse echo &quot;Install $SERVICE_NAME...&quot;; chmod +x $EXEC_FILE # 创建systemd服务文件 tee $SYSTEM_CONF &gt; /dev/null &lt;&lt;EOT[Unit]Description=$SERVICE_NAME ServiceAfter=network.target[Service]Type=simpleRestart=alwaysRestartSec=10ExecStart=$START_CMDWorkingDirectory=$PROJECT_DIR[Install]WantedBy=multi-user.targetEOT # 重新加载systemd服务 systemctl daemon-reload # 启动DeviceBus服务 可能要改配置 先不启动 systemctl start $SERVICE_NAME # 设置开机自启动 systemctl enable $SERVICE_NAME echo &quot;Install $SERVICE_NAME end&quot; echo &quot;Start program with systemctl start $SERVICE_NAME&quot;fi Learn more Bilibili Video Arch wiki","link":"/2023/09/11/Linux-service-register-script/"},{"title":"Lua raise error: C stack overflow","text":"C stack overflow在cpp中调用lua虚拟机，出现异常。 其实本质上是lua层代码调用了超过指定数量 LUAI_MAXCCALLS（默认200次）的cfunc导致的bug 1. require死循环通常来说，大概率发生在require死循环中，排查require相互引用改为惰性引用或者修改程序结构可以解决 当然如果在c++中直接调用luaState运行，并且嵌入了很多c结构体的，可以在源码lstate.c中直接在C stack overflow处加入断点，即对具体业务分析对象在何处死循环 2. lua调用cfunc异常12345678int luaCall(lua_State* L) { try { // 在这个业务逻辑里面存在更深层次的c层userdata调用引发了未处理的异常 lua_pcall(L, 0, r, 0); } catch (std::expection&amp; ex) { // handler error }} 底层原理跟还是调用次数超过了LUAI_MAXCCALLS但可能是由于我们业务中存在很多c++层userdata对象的调用引发了异常导致，lua_pcall无法正常处理nCcalls计数导致 例如当C++层TimerUpdat时会调用上述luaCall，L-&gt;nCcalls计数加1luaCall调用的函数，在lua层对c++层数据库对象进行操作时，引发了未捕获异常 此时L-&gt;nCcalls计数再次加1由于异常退出了，导致nCcalls计数未能正常处理，从而导致计数一直增长 在处理数据库对象引发异常时捕获并处理抛出luaL_error 额外提供一个实用的打印堆栈的函数 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980void luaStackTrace(lua_State *L){ int i; int top = lua_gettop(L); printf(&quot;---- Begin Stack ----\\n&quot;); printf(&quot;Stack size: %i\\n\\n&quot;, top); for (i = top; i &gt;= 1; i--) { int t = lua_type(L, i); switch (t) { case LUA_TSTRING: printf(&quot;%i -- (%i) ----string: `%s'&quot;, i, i - (top + 1), lua_tostring(L, i)); break; case LUA_TBOOLEAN: printf(&quot;%i -- (%i) ----bool: %s&quot;, i, i - (top + 1), lua_toboolean(L, i) ? &quot;true&quot; : &quot;false&quot;); break; case LUA_TNUMBER: printf(&quot;%i -- (%i) ----number: %g&quot;, i, i - (top + 1), lua_tonumber(L, i)); break; case LUA_TTABLE: { printf(&quot;%i -- (%i) ---- %s\\n&quot;, i, i - (top + 1), lua_typename(L, t)); lua_pushnil(L); while (lua_next(L, i) != 0) { switch (lua_type(L, -2)) { case LUA_TSTRING: printf(&quot;| key ----string: `%s'&quot;, lua_tostring(L, -2)); break; case LUA_TBOOLEAN: printf(&quot;| key ----bool: %s&quot;, lua_toboolean(L, -2) ? &quot;true&quot; : &quot;false&quot;); break; case LUA_TNUMBER: printf(&quot;| key ----number: %g&quot;, lua_tonumber(L, -2)); break; default: printf(&quot;| key ---- %s&quot;, lua_typename(L, -2)); break; } printf(&quot;\\n&quot;); switch (lua_type(L, -1)) { case LUA_TSTRING: printf(&quot;| value ----string: `%s'&quot;, lua_tostring(L, -1)); break; case LUA_TBOOLEAN: printf(&quot;| value ----bool: %s&quot;, lua_toboolean(L, -1) ? &quot;true&quot; : &quot;false&quot;); break; case LUA_TNUMBER: printf(&quot;| value ----number: %g&quot;, lua_tonumber(L, -1)); break; default: printf(&quot;| value ---- %s&quot;, lua_typename(L, -1)); break; } printf(&quot;\\n&quot;); lua_pop(L, 1); } printf(&quot;%i -- (%i) table end&quot;, i, i - (top + 1)); break; } default: printf(&quot;%i -- (%i) ---- %s&quot;, i, i - (top + 1), lua_typename(L, t)); break; } printf(&quot;\\n&quot;); } printf(&quot;---- End Stack ----\\n&quot;); printf(&quot;\\n&quot;);}","link":"/2023/09/15/Lua-raise-error-C-stack-overflow/"},{"title":"Lua 源码中 l_likely, l_unlikey 是什么意思","text":"最近在排查c++程序内部调用lua_pcall时产生C stack overflow异常，研究问题时发现lua源码中存在一些likely调用,其实在其他代码中也见到过类似的调用，那么我们今天就来探究一下它到底是什么逻辑 lua代码： 12345678910111213141516171819202122232425262728// 校验c层的nCcalls调用计数// getCcalls函数返回lua层调用c层回调call的计数值// LUAI_MAXCCALLS 是调用限制的宏定义 5.4中定义为200// 即如果调用超过200时 调用luaE_checkcstack 引发异常if (l_unlikely(getCcalls(L) &gt;= LUAI_MAXCCALLS)) luaE_checkcstack(L);//////////////////////////////////////#define l_likely(x) luai_likely(x)#define l_unlikely(x) luai_unlikely(x)/*** macros to improve jump prediction, used mostly for error handling** and debug facilities. (Some macros in the Lua API use these macros.** Define LUA_NOBUILTIN if you do not want '__builtin_expect' in your** code.)*/#if !defined(luai_likely) #if defined(__GNUC__) &amp;&amp; !defined(LUA_NOBUILTIN) #define luai_likely(x) (__builtin_expect(((x) != 0), 1)) #define luai_unlikely(x) (__builtin_expect(((x) != 0), 0)) #else #define luai_likely(x) (x) #define luai_unlikely(x) (x) #endif#endif 好，直到这里我们发现这是一个编译时的宏定义，甚至在某些特定情况下l_likely和l_unlikely调用了和没调用没区别即不论if (l_likely(r))还是if (l_unlikely(r)) 在逻辑语义上是完全等价于if (r) 那么，什么是__builtin_expect ?123456789101112Built-in Function: long __builtin_expect (long EXP, long C)You may use `__builtin_expect' to provide the compiler with branch prediction information.The return value is the value of EXP, which should be an integral expression. The value of C must be a compile-time constant. The semantics of the built-in are that it is expected that EXP == C.For example: if (__builtin_expect (x, 0)) foo ();would indicate that we do not expect to call `foo', since we expect `x' to be zero. Since you are limited to integral expressions for EXP, you should use constructions such as if (__builtin_expect (ptr != NULL, 1)) error ();when testing pointer or floating-point values. 乍一看满头问号，预测信息？ 不对啊，只有我写代码才是玄学才对啊（不是 其实是这样的，这个函数是gcc提供的为编译优化处理的函数，并不会对逻辑语义造成影响例如: 12345if (l_ulikely(&lt;绝大多数情况都不会为真&gt;)) { // do if} else { // do else} 上述语句中，在gcc(&gt;=2.96)编译的情况下，编译器将会把else部分的逻辑进行编译优化，以期待减少指令跳转带来的性能损耗那么具体优化了啥呢？现在处理器都是流水线的，有些里面有多个逻辑运算单元，系统可以提前取多条指令进行并行处理，但遇到跳转时，则需要重新取指令，这相对于不用重新去指令就降低了速度。目的是增加条件分支预测的准确性，cpu会提前装载后面的指令，遇到条件转移指令时会提前预测并装载某个分支的指令。unlikely 表示你可以确认该条件是极少发生的，相反 likely 表示该条件多数情况下会发生。编译器会产生相应的代码来优化 cpu 执行效率。 总结不论if (l_likely(r))还是if (l_unlikely(r)) 在逻辑语义上是完全等价于if (r) 我们可能会在大多数地方找到不一样名字关于likely/unlikely的宏定义，函数本质上是为了编译时优化逻辑跳转减少重新取指令的开销，并不会影响实际的逻辑语义 因此，在你十分确信绝大多数情况下为真时使用likely,或者在你十分确信绝大多数情况下为假时使用unlikely.例如问题最开始的if (l_unlikely(getCcalls(L) &gt;= LUAI_MAXCCALLS)), 因为正常情况下不可能引发C Stack Overflow的异常","link":"/2022/01/07/Lua-%E6%BA%90%E7%A0%81%E4%B8%AD-l-likely-l-unlikey-%E6%98%AF%E4%BB%80%E4%B9%88%E6%84%8F%E6%80%9D/"},{"title":"Mysql主从同步配置","text":"对于环境隔离，读写分离的情况，有些情况下我们需要用到mysql的主从同步。以下介绍如何使用docker创建一个主从同步的数据库服务 0. 环境假设由于测试在本机创建两个数据库服务，因此以下ip都按master_ip,slave_ip代之用于区分，实际过程请按照实际情况填写 即主数据库为 master_ip:3308从数据库为 slave_ip:3309 1. 创建两个db，一个master监听3308，一个slave监听33091234567# log-bin=mysql-bin以及server-id=1的设置可以通过my.cnf/my.ini配置修改，也可以通过docker启动mysql的命令行设置，注意修改my.cnf/my.ini配置后需要重启mysql# 建立一个master db，监听3308docker run --name mysql_master -e MYSQL_ROOT_PASSWORD=aaa123 -p 3308:3306 -d mysql:5.7 --log-bin=mysql-bin --server-id=1# 建立一个slave db, 监听3309docker run --name mysql_slave -e MYSQL_ROOT_PASSWORD=aaa123 -p 3309:3306 -d mysql:5.7 --log-bin=mysql-bin --server-id=2 2. 登陆主库master db，设置专门为slave建立的用户并赋予权限123456789mysql -h master_ip -P 3308 -u root -p &gt; CREATE USER 'backup'@'slave_ip' IDENTIFIED BY 'backup_password';&gt; GRANT REPLICATION SLAVE ON *.* TO 'backup'@'slave_ip';&gt; FLUSH PRIVILEGES;&gt; SHOW MASTER STATUS;File Positionmysql-bin.000003 1737 记录下最后SHOW MASTER STATUS返回结果中的File和Position注意 backup_password填自己设定的值即可，下面会用到 3. 登陆从库slave db，设置master的链接方式123456mysql -h slave_ip -P 3309 -u root -p &gt; STOP SLAVE;&gt; change master to MASTER_HOST='master_ip', MASTER_PORT=3308, MASTER_USER='backup',MASTER_PASSWORD='backup_password',MASTER_LOG_FILE='mysql-bin.000003',MASTER_LOG_POS=1737;&gt; START SLAVE;&gt; SHOW SLAVE STATUS; 这里注意一下backup_password需要填入第2步中设置的backup_password，MASTER_LOG_FILE以及MASTER_LOG_POS也是根据第2步中SHOW MASTER STATUS返回设置的设置成功时，SHOW SLAVE STATUS;会返回 Slave_IO_Running 和 Slave_SQL_Running都是Yes即可 4. 回到主库，尝试创建数据表插入数据等操作，并确认从库会自动同步即可","link":"/2023/10/17/Mysql%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E9%85%8D%E7%BD%AE/"},{"title":"NSIS打包C# 程序","text":"NSIS是一个Nullsoft脚本安装系统（英语：Nullsoft Scriptable Install System，缩写：NSIS）为一个开放源代码脚本驱动的封装安装档用工具。可以用其脚本语言自定安装的流程，同时支持多种语系的安装接口。 安装NSIS有些人建议安装Unicode NSIS，NSIS3.0.1版本已经兼容了unicode，除非是老版本的，可以考虑安装Unicode NSIS。NSIS下载地址 下载安装完成后，可以在桌面看到一个NSIS的图标，先别急着打开它，现在我们还用不上它。 安装插件安装一些常用插件（以下插件均为按需安装，如果不需要也可以选择不安装） AccessControl.dll : 它提供了一组与Windows NT访问控制列表（ACL）管理相关的功能，相当于设定目录权限的功能。 下载地址KillProcDLL.dll：关闭指定名称的exe,用于卸载时关闭进程。下载地址liteFirewall.dll： 关闭防火墙下载地址UAC.dll，UAC.nsh 下载地址以上插件下载解压后，将dll文件复制到C:\\Program Files (x86)\\NSIS\\Plugins内，nsh文件复制到C:\\Program Files (x86)\\NSIS\\Include内。 添加NSIS配置下载一个Exmaple这个例子源自，在此鸣谢原作者。这里主要逻辑在Exmaple.nsi内，其他都是一些资源文件，简单修改一下配置： 12345678910111213141516171819202122; !define 用于声明一个常量!define PRODUCT_NAME &quot;YuanJin&quot; 产品名称!define PRODUCT_VERSION &quot;1.0&quot; 版本号!define PRODUCT_PUBLISHER &quot;YuanJin&quot; 发布者!define PRODUCT_WEB_SITE &quot;http://www.yuanjin.io/&quot; 产品官网，这将在安装完成后显示在开始程序栏内的快捷键!define PRODUCT_STARTUP_APP &quot;YuanJin.exe&quot; 注意更改这个，这个就是你需要打包的exe文件，程序安装完成时将自动执行; 主要讲一下依赖，个别程序会需要第三方依赖，我是将第三方依赖加入到DIR_TO_INSTALL中，如下配置Section &quot;ExampleSection01&quot; SEC01 CreateDirectory &quot;$SMPROGRAMS\\${PRODUCT_NAME}&quot; SetOutPath $INSTDIR SetOverwrite try File &quot;..\\Example\\DIR_TO_INSTALL\\JsonFx.dll&quot; File &quot;..\\Example\\DIR_TO_INSTALL\\JsonFx.xml&quot; File &quot;..\\Example\\DIR_TO_INSTALL\\Newtonsoft.Json.dll&quot; File &quot;..\\Example\\DIR_TO_INSTALL\\Newtonsoft.Json.xml&quot; File &quot;..\\Example\\DIR_TO_INSTALL\\YuanJin.exe.config&quot; File &quot;..\\Example\\DIR_TO_INSTALL\\YuanJin.pdb&quot; File &quot;favico.ico&quot; CreateShortCut &quot;$SMPROGRAMS\\${PRODUCT_NAME}\\$(ShortCutUninstall)&quot; &quot;$INSTDIR\\uninst2.exe&quot; &quot;&quot; &quot;$INSTDIR\\${APPLICATION_ICON}&quot; 0SectionEnd 打包程序现在我们回到桌面，打开NSIS程序，你会看到一个很精致小巧的界面，没错不要怀疑：），雾~点击Complier NSI scripts —-&gt; load script —-&gt;找到刚刚编辑的Exmaple.nsi双击，如果一切正常你将会看到Test Installer可以被点击了。你会在Exmaple/output中看到打包好的exe了。 NSIS中文文档","link":"/2022/01/06/NSIS%E6%89%93%E5%8C%85C-%E7%A8%8B%E5%BA%8F/"},{"title":"RDP内网穿透","text":"用于有公网服务器的内网穿透搭建 https://github.com/fatedier/frp 是一款内网穿透服务的开源服务，跨平台服务端和客户端 frp服务器 1.1 下载服务器 在该界面下载最新的压缩包 , (压缩包内包含了客户端和服务端，因此等会windows上也要下载一次做客户端) ‣ 1.2 配置frp服务器 将压缩包内容解压到自定义目录内，例如我的应用都会装到/opt目录下 以下假设解压到/opt/frp内 服务端配置文件/opt/frp/frps.ini 1234567# frps.ini[common]# 服务器绑定的端口 这个端口需要外网可以访问bind_port = 7000# 用来做服务器校验的， 服务器和客户端设置为一致即可，相当于密码建议修改token = aabbccdd 1.3 尝试启动服务 /opt/frp/frps -c /opt/frp/frps.ini 正常启动就ok 可以按ctrl+c退出 1.4 启动服务器 可以直接使用上述测试方式启动/opt/frp/frps -c /opt/frp/frps.ini 但是建议改为systemctl启动 这样就能达到开机自启的效果了 当然supervisor，pm2等这些也都可以 frp客户端 1.1 下载客户端 在该界面下载最新的压缩包 , (压缩包内包含了客户端和服务端) ‣ 2.2 配置客户端 将压缩包解压到自己建的安装目录内 以下假设为 F:\\app\\frp 修改F:\\app\\frp\\frpc.ini 123456789101112131415161718# frpc.ini[common]# 服务器地址server_addr = x.x.x.x# 服务器绑定的端口 bind_port server_port = 7000# 需要和服务器的token配置一致token = aabbccdd[rdp]# rdp服务协议type = tcp# 本地的回环地址local_ip = 127.0.0.1# rdp端口 默认是3389local_port = 3389# rdp服务在服务器暴露的端口remote_port = 6000 2.3 尝试启动 打开powershell（按win键入powershell搜索，点击powershell） 输入如下命令 1F:\\app\\frp\\frpc.exe -c F:\\app\\frp\\frpc.ini 如果正常启动（如果你无法判断什么是正常启动，直接通过x.x.x.x:6000测试连接rdp服务测试），则可以进入下一步 2.4 设置开机自启动 新建文件F:\\app\\frp\\start_frpc.vbs，键入如下命令 12'start_frpc.vbsCreateObject(&quot;WScript.Shell&quot;).Run &quot;&quot;&quot;F:\\app\\frp\\frpc.exe&quot;&quot;&quot; &amp; &quot;-c&quot; &amp; &quot;&quot;&quot;F:\\app\\frp\\frpc.ini&quot;&quot;&quot;,0 建议通过任务计划程序实现开机自启 常规 不管用户是否登录都要运行 勾选不存储密码 触发器 改成登陆时 操作 启动程序 程序或脚本填 F:\\app\\frp\\start_frpc.vbs或者通过浏览找到该文件 条件 电源内选项 勾选网络 只有在以下网络连接可用才启动","link":"/2023/09/11/RDP%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/"},{"title":"Server certificate verification failed","text":"在自建服务时原本运行好好的无法返回server certificate verification failed. curl https://xxx.xxx.xxx 时会告知，curl: (60) server certificate verification failed. CAfile: /etc/ssl/certs/ca-certificates.crt CRLfile: none 但是https网址可以在浏览器内被正常打开，但是通过命令例如git，curl等请求报错，客户端openssl解析证书时存在问题以我遇到问题的letsencrypt证书为例，通常时因为请求客户端的openssl，letsencrypt证书签名链种包含了一条ISRG Root X1自签名证书链，浏览器会校验该证书链拿到正确的，但是openssl1.0.2不支持此逻辑它依旧拿了旧的过期的DST Root CA X3 临时解决：如果是git的话设置 git config --global http.sslverify false如果是curl的话请求时加 -k 参数跳过ssl证书认证 永久解决：在发起请求出错的机器上，升级依赖软件包 sudo apt update &amp;&amp; sudo apt upgrade 通过curl请求域名，curl https://xxx.xxx.xxx 不报错就说明好了 参考： https://letsencrypt.org/docs/dst-root-ca-x3-expiration-september-2021/ https://community.letsencrypt.org/t/production-chain-changes/150739 https://www.openssl.org/blog/blog/2021/09/13/LetsEncryptRootCertExpire/ https://docs.certifytheweb.com/docs/kb/kb-202109-letsencrypt/ https://stackoverflow.com/questions/21181231/server-certificate-verification-failed-cafile-etc-ssl-certs-ca-certificates-c","link":"/2023/09/12/Server-certificate-verification-failed/"},{"title":"Strace","text":"Strace是Linux环境下用于调试诊断应用程序调用systemcall的工具。 由于Strace只检测系统调用，因此Strace只是一个分析的侧面。例如：命令perl -e 'while(1){}'不会产生任何系统调用 系统调用包括以下几个方面file, process, network, signal, ipc, desc， 默认将检测所有系统调用即all 使用Strace统计运行期间系统调用占比12345678910111213$ sudo strace -f -c mainstrace: Process 30879 detached% time seconds usecs/call calls errors syscall------ ----------- ----------- --------- --------- ---------------- 64.79 2.184606 35236 62 3 futex 28.13 0.948503 566 1675 1 clock_nanosleep 2.85 0.096019 8 12105 getsockopt 1.35 0.045417 3 16768 mprotect 0.82 0.027561 7 4002 3633 recvfrom 0.65 0.021963 3 7108 lseek ...------ ----------- ----------- --------- --------- ----------------100.00 3.371847 55680 5957 total 使用Strace 记录程序运行期间的系统调用可以通过添加-tt记录调用时间戳，与程序日志对比可区分出程序各个阶段的系统调用 1234567891011$ sudo strace -f -tt -T -o /tmp/test/trace.log main$ cat /tmp/test/trace.log18721 21:02:31.936942 execve(&quot;/bin/bash&quot;, [&quot;bash&quot;, &quot;-c&quot;, &quot;APOWO_SERVER_ROOT=/home/never/wo&quot;...], 0x7ffef5c46408 /* 14 vars */) = 0 &lt;0.000077&gt;18721 21:02:31.937082 brk(NULL) = 0x563070e9c000 &lt;0.000017&gt;18721 21:02:31.937133 arch_prctl(0x3001 /* ARCH_??? */, 0x7ffe20222180) = -1 EINVAL (Invalid argument) &lt;0.000017&gt;18721 21:02:31.937183 access(&quot;/etc/ld.so.preload&quot;, R_OK) = -1 ENOENT (No such file or directory) &lt;0.000019&gt;PID 调用时间 系统调用名称 返回 消耗时间 18721 21:02:31.936942 execve(&quot;/bin/bash&quot;, [&quot;bash&quot;, &quot;-c&quot;, &quot;APOWO_SERVER_ROOT=/home/never/wo&quot;...], 0x7ffef5c46408 /* 14 vars */) = 0 &lt;0.000077&gt; 参考https://linux.die.net/man/1/strace","link":"/2022/01/07/Strace/"},{"title":"关于Tinc VPN的搭建","text":"关于Tinc 是一种相对小众的VPN方案。但是支持很多环境的安装，例如ubuntu，centos都可以用自带的包管理工具安装。下面是对于Ubuntu的示例 准备两台（至少）机器至少要有一台机器有稳定的公网IP 安装在两台机器上都安装tincapt update &amp;&amp; apt install -y tinc 配置以下分别命名两台机器为pek，lax下面我们建一个tinc名为test 网卡tinc0，内网网段设置为172.16.0.0/28 创建test目录两边都执行mkdir /etc/tinc/test &amp;&amp; mkdir /etc/tinc/test/hosts 编辑tinc.conf即tinc的配置文件vim /etc/tinc/test/tinc.conf分两部分 pek写入 123456Interface = tinc0Name = pekMode = switchConnectTo = lax# In newer versions (&gt;= 1.1) you can use AutoConnect instead# AutoConnect = yes lax写入 12345Interface = tinc0Name = laxMode = switch# In newer versions (&gt;= 1.1) you can use AutoConnect instead# AutoConnect = yes 编辑tinc-up，即当启用test时需要tinc执行的脚本vim /etc/tinc/test/tinc-uppek写入 1234567891011#!/bin/sh# set the interface upip link set dev $INTERFACE up# add transfer networksip addr add 172.16.0.1/28 dev $INTERFACE scope link# add routes# ip route add 172.16.0.0/28 dev $INTERFACE src 172.16.0.2 lax写入 1234567891011#!/bin/sh# set the interface upip link set dev $INTERFACE up# add transfer networksip addr add 172.16.0.2/28 dev $INTERFACE scope link# add routes# ip route add 172.16.0.0/28 dev $INTERFACE src 172.16.0.1 编辑tinc-down，即当关闭test时需要tinc执行的脚本vim /etc/tinc/test/tinc-down两边都键入 1234#!/bin/ship link set $INTERFACE down 给予tinc-up和tinc-down脚本添加执行权限chmod +x tinc-* 创建tinc之间交互需要的秘钥，cd /etc/tinc/test &amp;&amp; tincd -K4096 -n test 交换lax和pek的秘钥将lax上的/etc/tinc/test/hosts/lax的内容写入pek的/etc/tinc/test/hosts/lax文件内 并在第一行加入Address=&lt;lax的外网IP&gt;将pek上的/etc/tinc/test/hosts/pek的内容写入pek的/etc/tinc/test/hosts/pek文件内 并在第一行加入 Address=&lt;pek的外网IP&gt;简单的来说就是交换两台机器彼此的秘钥，并写入IP地址 将test写入tinc的nets.boot中,并重启tincecho 'test' &gt;### /etc/tinc/nets.boot &amp;&amp; service tinc restart 之后就可以用ifconfig来查看是否有新加的tinc0网卡，以及IP地址。可以用ping来校验双方是否联通 参考Tinc docDN42","link":"/2022/01/06/VPN%E7%9A%84%E6%90%AD%E5%BB%BA/"},{"title":"Virtualenvwrapper","text":"通过命令pip install virtualenvwrapper安装 123# 将下面代码写入SHELL的环境变量，通过相关搜索得到建议ubuntu用户将其添加如~/.bash_profile文件内，deepin下好像没有，因此我将其添加进了~/.bashrcexport WORKON_HOME=~/Envssource /usr/local/bin/virtualenvwrapper.sh 添加好环境变量之后执行如下语句 123456mkdir -p $WORKON_HOME #为虚拟环境建立一个文件夹，仅第一次需要echo 'cd $VIRTUAL_ENV'&gt;&gt;$WORKON_HOME/postactivate #设置进入虚拟环境时的默认目录mkvirtualenv $envname #创建一个虚拟环境，和virtual一样可以指定参数例如-pworkon $envname #实际上当你新建的时候，你就会进入这个虚拟环境，这条命令用于你下一次再进入或切换到envname环境下deactivate #退出虚拟环境rmvirtualenv $envname #删除虚拟环境","link":"/2022/01/06/Virtualenvwrapper/"},{"title":"hexo添加音乐播放","text":"var options = {\"narrow\":false,\"autoplay\":true,\"showlrc\":3,\"mode\":\"random\",\"mutex\":true,\"theme\":\"#e6d0b2\",\"preload\":\"auto\",\"listmaxheight\":\"513px\",\"width\":\"50%\",\"music\":[{\"title\":\"Something Just Like This\",\"author\":\"Coldplay\",\"url\":\"/music/SomethingJustLikeThis.mp3\",\"pic\":\"/music/Coldplay.jpg\",\"lrc\":\"/music/SomethingJustLikeThis-Coldplay.lrc\"},{\"title\":\"发如雪\",\"author\":\"周杰伦\",\"url\":\"/music/发如雪.mp3\",\"pic\":\"/music/Coldplay.jpg\",\"lrc\":\"/music/发如雪-周杰伦.lrc\"},{\"title\":\"Viva La Vida\",\"author\":\"Coldplay\",\"url\":\"/music/VivaLaVida.mp3\",\"pic\":\"/music/Coldplay.jpg\",\"lrc\":\"/music/VivaLaVida-Coldplay.lrc\"},{\"title\":\"我记得\",\"author\":\"赵雷\",\"url\":\"/music/我记得.mp3\",\"pic\":\"/music/我记得.jpg\",\"lrc\":\"/music/我记得-赵雷.lrc\"},{\"title\":\"晚婚\",\"author\":\"江蕙\",\"url\":\"/music/晚婚.mp3\",\"pic\":\"/music/晚婚.jpg\",\"lrc\":\"/music/晚婚-江蕙.lrc\"}]}; options.element = document.getElementById(\"aplayer-ERFDshqx\"); var ap = new APlayer(options); window.aplayers || (window.aplayers = []); window.aplayers.push(ap); 安装hexo-tag-aplayer npm i hexo-tag-aplayer,在 source/music 目录中添加下载的歌曲，歌词，封面。这里给一个免费的音乐下载网站,在文章中写入如下内容即可: 1{% aplayer title author url [picture_url, narrow, autoplay, width:xxx, lrc:xxx] %} 下面给出一个播放列表的示例。 1234567891011121314151617181920212223242526272829303132333435363738394041424344{% aplayerlist %}{ &quot;narrow&quot;: false, &quot;autoplay&quot;: true, &quot;mode&quot;: &quot;random&quot;, &quot;showlrc&quot;: 3, &quot;mutex&quot;: true, &quot;theme&quot;: &quot;#e6d0b2&quot;, &quot;preload&quot;: &quot;auto&quot;, &quot;listmaxheight&quot;: &quot;513px&quot;, &quot;width&quot;: &quot;50%&quot;, &quot;music&quot;: [ { &quot;title&quot;: &quot;Something Just Like This&quot;, &quot;author&quot;: &quot;Coldplay&quot;, &quot;url&quot;: &quot;/music/SomethingJustLikeThis.mp3&quot;, &quot;pic&quot;: &quot;/music/Coldplay.jpg&quot;, &quot;lrc&quot;: &quot;/music/SomethingJustLikeThis-Coldplay.lrc&quot; }, { &quot;title&quot;: &quot;Viva La Vida&quot;, &quot;author&quot;: &quot;Coldplay&quot;, &quot;url&quot;: &quot;/music/VivaLaVida.mp3&quot;, &quot;pic&quot;: &quot;/music/Coldplay.jpg&quot;, &quot;lrc&quot;: &quot;/music/VivaLaVida-Coldplay.lrc&quot; }, { &quot;title&quot;: &quot;我记得&quot;, &quot;author&quot;: &quot;赵雷&quot;, &quot;url&quot;: &quot;/music/我记得.mp3&quot;, &quot;pic&quot;: &quot;/music/我记得.jpg&quot;, &quot;lrc&quot;: &quot;/music/我记得-赵雷.lrc&quot; }, { &quot;title&quot;: &quot;晚婚&quot;, &quot;author&quot;: &quot;江蕙&quot;, &quot;url&quot;: &quot;/music/晚婚.mp3&quot;, &quot;pic&quot;: &quot;/music/晚婚.jpg&quot;, &quot;lrc&quot;: &quot;/music/晚婚-江蕙.lrc&quot; } ]}{% endaplayerlist %}","link":"/2023/11/16/hexo%E6%B7%BB%E5%8A%A0%E9%9F%B3%E4%B9%90%E6%92%AD%E6%94%BE/"},{"title":"关于Core dump(核心转储)","text":"core dump是程序运行时，在进程收到某些信号而终止运行时，将此时进程地址空间的内容以及有关进程状态的其他信息写入一个磁盘文件。 对应会产生core dump的信号 Signal Action Comment SIGQUIT Core Quit from keyboard SIGILL Core Illegal Instruction SIGABRT Core Abort signal from abort SIGSEGV Core Invalid memory reference SIGTRAP Core Trace/breakpoint trap 我们可以通过使用gdb查core dump文件，最后崩溃时的信息，来进行debug为了更好的查看阅读core dump文件, linux下需要进行以下配置 设置core文件生成位置， 默认为当前目录可以修改/proc/sys/kernel/core_pattern，将core文件生成到指定目录下 12mkdir /coresecho &quot;/cores/core.%t.%e.%p&quot; | sudo tee /proc/sys/kernel/core_pattern 参数包含 1234567%e Executable name%h Hostname%p PID of dumped process%s Signal causing dump%t Time of dump%u UID%g GID 设置系统ulimit core size可以通过ulimit -c 查看当前 core size， 默认为0，即不会生成core dump文件 通过ulimit -c unlimited设置当前会话中的ulimit， 退出或者新开会话会失效 为docker 设置ulimit， 默认会跟随 dockerd的配置，也可以在运行时指定 docker run --ulimit core=-1 --security-opt seccomp=unconfined -v /cores:/cores &lt;后续命令&gt; 在程序中直接设定，下面是一个例子 12345678910111213141516171819202122232425262728293031323334#include &lt;unistd.h&gt;#include &lt;sys/time.h&gt;#include &lt;sys/resource.h&gt;#include &lt;stdio.h&gt;#define CORE_SIZE -1int main(){ struct rlimit rlmt; if (getrlimit(RLIMIT_CORE, &amp;rlmt) == -1) { return -1; } printf(&quot;Before set rlimit CORE dump current is:%d, max is:%d\\n&quot;, (int)rlmt.rlim_cur, (int)rlmt.rlim_max); rlmt.rlim_cur = (rlim_t)CORE_SIZE; rlmt.rlim_max = (rlim_t)CORE_SIZE;#if DEBUG // 主要是这句 设定 core size if (setrlimit(RLIMIT_CORE, &amp;rlmt) == -1) { return -1; } #endif if (getrlimit(RLIMIT_CORE, &amp;rlmt) == -1) { return -1; } printf(&quot;After set rlimit CORE dump current is:%d, max is:%d\\n&quot;, (int)rlmt.rlim_cur, (int)rlmt.rlim_max); /*测试非法内存，产生core文件*/ int *ptr = NULL; *ptr = 10; return 0;} 由于我们大多数工程测试时都是跑在clion+wsl环境中的， 当clion启动wsl时会通过 wsl另外启动一个sh的壳导致我们在系统内部设置的ulimit失效，所以我们项目中选择在程序内设定。 通过C:\\Windows\\system32\\wsl.exe --distribution Ubuntu-18.04 --exec /bin/sh -c &quot;ulimit -c&quot;可以验证 添加编译参数，在查看core dump文件时可以拿到更详细的信息1234567CMakeLists.txt add_definitions(-DDEBUG=true) add_definitions(-DRELEASE=false) # core dump config add_definitions(&quot;$ENV{CXXFLAGS} -O0 -g&quot;) SET(CMAKE_CXX_FLAGS_DEBUG &quot;$ENV{CXXFLAGS} -O0 -g&quot;) 至此 当程序异常退出时，我们可以在debug环境下愉快的拿到core文件了假设core文件为/cores/core.1630405848.pixelpai.19,我们就可以通过gdb解析对应的文件bt # 获取最后退出堆栈的详细信息frame 3 # 简写 f 3 切到第3个frame 并输出相关代码p value # 展示所在帧value对象的值up # 移到上一个帧down # 移到下一个帧 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556gdb main /cores/core.1630405848.pixelpai.19...GNU gdb (Ubuntu 8.1.1-0ubuntu1) 8.1.1Copyright (C) 2018 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type &quot;show copying&quot;and &quot;show warranty&quot; for details.This GDB was configured as &quot;x86_64-linux-gnu&quot;.Type &quot;show configuration&quot; for configuration details.For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;.Find the GDB manual and other documentation resources online at:&lt;http://www.gnu.org/software/gdb/documentation/&gt;.For help, type &quot;help&quot;.Type &quot;apropos word&quot; to search for commands related to &quot;word&quot;...Reading symbols from cmake-build-debug/build/bin/main...done.[New LWP 17765][New LWP 2336][New LWP 29510][New LWP 11379][New LWP 2335][New LWP 2334][New LWP 20475][New LWP 20476][New LWP 20477]warning: Could not load shared library symbols for 2 libraries, e.g. ./cjson.so.Use the &quot;info sharedlibrary&quot; command to see the complete listing.Do you need &quot;set solib-search-path&quot; or &quot;set sysroot&quot;?[Thread debugging using libthread_db enabled]Using host libthread_db library &quot;/lib/x86_64-linux-gnu/libthread_db.so.1&quot;.Core was generated by `/home/never/work/pixelpai_server/cmake-build-debug/build/bin/main -props /home/'.Program terminated with signal SIGABRT, Aborted.#0 raise (sig=&lt;optimized out&gt;) at ../sysdeps/unix/sysv/linux/raise.c:5050 ../sysdeps/unix/sysv/linux/raise.c: No such file or directory.[Current thread is 1 (Thread 0x7fca28917700 (LWP 17765))](gdb) bt#0 raise (sig=&lt;optimized out&gt;) at ../sysdeps/unix/sysv/linux/raise.c:50#1 0x0000562abaf64e47 in console::handler (sig=11) at /home/never/work/pixelpai_server/src/server/main/console_linux.cpp:244#2 &lt;signal handler called&gt;#3 0x00007fca316e0108 in Sprite::getSpriteSerialize (this=0x7fca00a66d00) at /home/never/work/pixelpai_server/src/server/world/virtualworld/scene/sprite.cpp:595#4 0x00007fca3169a87a in Scene::sendEnterSceneToAll (this=0x7fca0217ba60, actorId=1685436067) at /home/never/work/pixelpai_server/src/server/world/virtualworld/scene/scene.cpp:535...(gdb) frame 3#3 0x00007fca316e0108 in Sprite::getSpriteSerialize (this=0x7fca00a66d00) at /home/never/work/pixelpai_server/src/server/world/virtualworld/scene/sprite.cpp:595(gdb) p animationSptr$1 = std::shared_ptr&lt;IAnimation&gt; (empty) = {get() = 0x0}(gdb) p spriteSptr$2 = std::shared_ptr&lt;op_client::Sprite&gt; (use count 1, weak count 0) = {get() = 0x7fca0d84cea0}(gdb) up#4 0x00007fca3169a87a in Scene::sendEnterSceneToAll (this=0x7fca0217ba60, actorId=1685436067) at /home/never/work/pixelpai_server/src/server/world/virtualworld/scene/scene.cpp:535535 auto characterProto = pCharacter-&gt;getSpriteSerialize();(gdb) down#3 0x00007fca316e0108 in Sprite::getSpriteSerialize (this=0x7fca00a66d00) at /home/never/work/pixelpai_server/src/server/world/virtualworld/scene/sprite.cpp:595 参考https://ctring.github.io/blog/2021/how-to-get-core-dump-in-a-Docker-container/https://le.qun.ch/en/blog/core-dump-file-in-docker/https://zhuanlan.zhihu.com/p/24311785https://www.cnblogs.com/hazir/p/linxu_core_dump.html","link":"/2022/01/07/%E5%85%B3%E4%BA%8ECore-dump-%E6%A0%B8%E5%BF%83%E8%BD%AC%E5%82%A8/"},{"title":"关于Git","text":"Git命令解释，假设你是&lt;&lt;异世界好哥哥历险记&gt;&gt;的编剧，咱们组使用阿里云盘对剧本压缩包保存方便随时随地可以在任意地方写作(ps:不要吐槽设定，都是剧情需要) Branch 分支每个分支就像是剧本中的不同剧情支线。例如，煤老板A说要注资但是要改剧本里面加个女二，这个剧情支线可以作为分支，分支名可以叫”XXX无惨”，再比如”送审13.0.23.20240123”等等。 123456$ git branch -a* master songshen13.0.23.20240123 remotes/origin/HEAD -&gt; origin/master remotes/origin/xxxwucan remotes/origin/master","link":"/2022/01/06/%E5%85%B3%E4%BA%8EGit/"},{"title":"关于游戏同步的二三事","text":"网络游戏同步法则 定义通常来说的状态同步，即狭义上的状态同步，即在状态发生变化时将变动的数据同步给客户端所谓帧同步其实是指以一帧数据为单位进行同步，但是通常来说我们认为的帧同步是 锁定帧同步（或者变种）那么广义上来说，其实存在既是帧同步又是状态同步，即以帧为单位的状态同步 帧同步基础共识实现目标A状态 + N个操作 = 确定的B状态 同步频率看到的一些同步频率都比较高2050次每秒，即20ms50ms本地测试例子时 同步频率超过100ms就能明显的感觉到操作卡顿的感觉 什么是锁定帧客户端将每帧执行的行为发送给服务端，服务端在每个步进结束时广播当前帧发生的变动，客户端演绎当前帧的变化标准定义下，服务端在未收集到当前帧所有客户端的上报前是不会发送当前帧同步的，即所有客户端需要等最慢的返回，才能获取返回 改进乐观锁:固定服务端的帧频，每个固定间隔将收到的客户端行为发送给客户端，并不确保收齐所有客户端当前帧的包，优点: 避免因为最慢的客户端导致全局卡顿缺点: 需要预测行为确保操作流畅，需要回滚修复预测偏差 预测帧尽量使得用户操作平滑通过对接收数据进行buffer缓存，按帧滑动并根据延迟缩放执行窗口和执行间隔达到平滑效果对于异常、回退帧添加插值帧，例如通过算法预测线性趋势下运行轨迹 帧回滚快进，消弭预测帧不正确导致的逻辑异常帧回滚是如何实现的，或者说帧切片如何保存现场并恢复，注意这里说的帧切片是逻辑帧而不是渲染帧如何校验是否一致，通用做法是将逻辑帧切片md5后发送到服务器，服务器进行广播 扩展思考：市面上多人游戏中，真的存在A物件运动会影响到10个以上其他物件运动的例子嘛？即在物理引擎展示中的子弹撞击方块山时的情景。如果存在是如何保存恢复逻辑帧的 为什么大多数都是UDP，而不是TCP多数例子都是通过udp传输的，通过业务帧序列号保证前端能感知到丢包，并且额外发包降低丢包率（例如每n帧有一帧关键帧，关键帧内包含1~n帧的内容）不过王者荣耀第一个测试版本也是tcp的，所以目前来说先用tcp先上 那么为什么不是tcp呢？ tcp通信本身在网络层存在拥塞控制，在网络状况不好的情况下会导致延迟稍大的情况引发更大的雪崩效应(可以通过切换拥塞算法或者修改TCP_NODELAY缓解，但是无法彻底避免) tcp本身时最求完全可靠和顺序性的，因此，丢包后会持续重传直至该包被确认，否则后续包也不会被上层接收，且重传采用指数避让策略，决定重传时间间隔的RTO (Retransmission Timeout)不可控制，Linux内核实现中最低值为200ms 可能存在的一些TCP优化方案： 切换拥塞算法bbr或者修改TCP_NODELAY 基于UDP定制传输层协议，引入顺序性和适当程度或者可调节程度的可靠性，修改流控算法。适当放弃重传，如：设置最大重传次数，即使重传失败，也不需要重新建立连接。比较知名的TCP加速开源方案有：quic、enet、kcp、udt。其中，quic是源自google的TCP替代方案，其主要目的是为了整合TCP协议的可靠性和UDP协议的速度和效率，其主要特性包括：避免前序包阻塞、减少数据包、向前纠错、会话重启和并行下载等，然而QUIC对标的是TCP+TLS+SPDY，相比其他方案更重，目前国内用于网络游戏较少。kcp的作者是国内优秀开发者，社区也发展良好，kcp的作者和社区开发者对enet、kcp、udt做了性能测试，详情可参见：https://github.com/skywind3000/kcp/wiki/KCP-Benchmark， 从测试情况可以看到，kcp表现不错，其次是enet，表现最差的是udt。 实现一个帧同步游戏我们需要什么 物理引擎至少需要满足以下两点根据冲量驱动对象移动碰撞分离，两个对象重叠后如何根据冲量，位置，时间信息计算出不分离后的位置 定点数运算，即一个数值稳定的物理引擎 拥有一个稳定的tick驱动物理引擎, 注意实现过程中帧会被其他逻辑拖累，我们需要一个独立并且稳定的帧频，这是物理引擎结果一致性的必要条件 增加udp通信 不是所有情况下udp都是通的，只有在udp连上的时候采用udp 因此传统做法都是先建立tcp 伪随机数 提高同步频率，尽量不要低于物理引擎渲染帧的3倍 同步逻辑参考： https://zentia.github.io/2019/04/22/frame-sync/ http://clintonbrennan.com/2013/12/lockstep-implementation-in-unity3d/ https://www.daimajiaoliu.com/daima/56b2d86c9ab0001 https://blog.codingnow.com/2018/08/lockstep.html https://zhuanlan.zhihu.com/p/344600774 http://www.vvbin.com/?p=860","link":"/2022/01/07/%E5%85%B3%E4%BA%8E%E6%B8%B8%E6%88%8F%E5%90%8C%E6%AD%A5%E7%9A%84%E4%BA%8C%E4%B8%89%E4%BA%8B/"},{"title":"口算二进制相互转换十六进制 以及拓展","text":"Why?hhhhh，没想到吧，我也没想到这东西还需要口算。国内一些考试需要，既然看了就记录下来吧。 用十六进制实战首先咱先来看下，一位十六进制数转换的数值。 十六进制 二进制 十进制 0 0000 0 1 0001 1 2 0010 2 3 0011 3 4 0100 4 5 0101 5 6 0110 6 7 0111 7 8 1000 8 9 1001 9 A 1010 10 B 1011 11 C 1100 12 D 1101 13 E 1110 14 F 1111 15 其实也大可不必全背下来，8以下的我相信大家都记得差不多，咱记住F就是1111，A是1010这两个锚点上下加减就够了。 二进制转十六进制给出一个二进制数 101110101010110101 从右到左，每4位一组将二进制进行分组 10 1110 1010 1011 0101， 为什么是4位一组，因为16等于2的4次方 将每组按十六进制转换 2 e a b 5 即 10 =&gt; 2, 1110 =&gt; e, 1010 =&gt; a, 1011 =&gt; b, 0101 =&gt; 5 最后将每组的转换值合并就可以获得对应进制的值 0x2eab5 十六进制转二进制其实是对二进制转十六进制的逆向 给出一个十六进制数 0x2eab5 为每位数展开为二进制数，这里需要注意，转为二进制后不足4位的要高位补0 0010 1110 1010 1011 0101 即 2 =&gt; 0010, e =&gt; 1110, a =&gt; 1010, b=&gt; 1011, 5 =&gt; 0101 最后将每组的转换值合并就可以获得转换后的二进制数 101110101010110101 其实扩展一下理论我们就可以得到二进制转2^n进制给出一个二进制数101110101010110101 从右到左，每n位一组将二进制分开 将每组按2^n进制转换 最后将每组的转换值合并就可以获得对应进制的值 2^n进制转二进制其实是对二进制转2^n进制的逆向 给出一个2^n进制数 为每位数展开为二进制数，这里需要注意，转为二进制后不足n位的要高位补0 最后将每组的转换值合并就可以获得转换后的二进制数 最后咱来看下题目哈 问： 内存按字节编址从A5000H到DCFFFH的区域其存储容量为__KB. 笔算说是。。。 1234567x = 0xDCFFFF - 0xA5000 + 1 = 0xDD0000 - 0xA5000 = 0x38000 = 0x0011 1000 * (2^12) // 后面3个0，转二进制就是 4*3 个 0 = 7 * (2^5) * (2^10) // 单位Bytes = 7 * 32 // 单位 KB = 224KB // 哒哒","link":"/2023/09/13/%E5%8F%A3%E7%AE%97%E4%BA%8C%E8%BF%9B%E5%88%B6%E8%BD%AC%E6%8D%A2/"},{"title":"回退git远程提交","text":"严格意义上来说，我们并不期待撤销一个已经提交的commit（虽然我们可以）下面给出4种解决方式，各有优缺点 使用git revert， 推荐但是比较麻烦 推荐使用git revert实现,将某一个提交生成一个完全相反的改动并提交 假设我们当前在main分支上commit如下， 当前在0223037e，期待回退到8266909f上 123commit 0223037ecommit 37a67ef8commit 8266909f 不包含merge提交此时我们只用依次回退0223037e以及37a67ef8即可12345$ git revert --no-commit 0223037e$ git revert --no-commit 37a67ef8# or 等价于$ git revert --no-commit 37a67ef8...0223037e 之后就正常commit+push即可 包含merge提交现在假定0223037e为merge提交，由dev merge main，我们当前在main分支上此时当我们执行git revert –no-commit 0223037e会报错 0223037e is a merge but no -m option was given.此时命令应该改为git revert --no-commit 0223037e -m 1剩下的逻辑跟不包含merge的提交一致即可-m参数后面是parentNumber, 官方文档是说 This option specifies the parent number (starting from 1) of the mainline and allows revert to reverse the change relative to the specified parent.翻译一下就是，当你在 B 分支上把 A merge 到 B 中，那么 B 就是merge commit 的 parent1，而 A 是 parent2。 直接git reset –hard， 省力但是如果有很多人和你协同工作的话， 藏好他们的刀 –hard 之后修改了git commit的index，因此期待提交时必须要通过git push -f,但是一旦你强行将push上去了之后，这回导致其他获取项目的同事需要面临无法正常git pull或者无法正常git push的情况 git diff –binary HEAD commit_sha_you_want_to_revert_to | git apply 存在缺陷部分无法通过git diff获取变更的无法使用该命令例如png 手动通过git reset –hard拿到一份想要的内容，git pull 拉去到最新的 然后将之前的内容覆盖回来朴实无华 参考：https://git-scm.com/docs/git-revert#git-revert--mparent-numberhttps://stackoverflow.com/questions/1463340/how-to-revert-multiple-git-commitshttps://juejin.cn/post/6844903590545506312","link":"/2022/01/06/%E5%9B%9E%E9%80%80git%E8%BF%9C%E7%A8%8B%E6%8F%90%E4%BA%A4/"},{"title":"常用服务端口占用","text":"我们常常会遇到在bind端口时返回，Address already in use。有时候机器可能之前运行了一些服务，当然我们可以通过各种netstat，lsof获得端口被谁占用了。下表只是做一个记录，有些一眼就看出来的端口可以方便排查 Port Des 1080 Shadowsock Proxy default port 2049 Network File System NFS 2181 Apache ZooKeeper 2375 Docker API HTTP 2376 Docker REST API HTTPS 3000 一些nodejs用的自定义服务喜欢用的默认监听端口，Express Create React App NextJS 3306 MySQL 4000 Phoenix, Jekyll 4001 etcd 4200 AngularJS 5353 Multicast DNS 5432 PostgreSQL 5900 VNC 6379 Redis 7890 Clash 8000 一些python用的自定义服务喜欢用的默认监听端口， Django 以及自带的http服务 8888 Jupyter Notebook 25565 Minecraft 27017 MongoDB 如果上面找不到，可以看看这个网站speedguide，输入端口查找看看是不是有更多信息","link":"/2023/10/08/%E5%B8%B8%E7%94%A8%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8/"},{"title":"监听随机端口","text":"业务上存在需求，一类服务监听随机端口，并由服务发现业务管理内部分配，那么我们如何实现监听随机端口呢？ 实际上将端口设置为0即可在规定范围内，分配一个可bind的端口 不论windows还是linux中bind函数传入port为0时，都将随机分配一个端口，相关文档可以查看下面的参考资料 随机端口的规定范围linux和windows的规定不一致，但是可以由proc配置/注册表等手段修改 Linux默认为32768 - 60999 之间在文件cat /proc/sys/net/ipv4/ip_local_port_range设定的范围内获取一个随机端口 Windows默认为 49152 - 65535 之间可以修改注册表HKLM\\SYSTEM\\CurrentControlSet\\Services\\Tcpip\\Parameters 修改值 如何获取bind成功的具体端口本身业务上随机bind成功之后，需要获取最后成功的bindPort上报给服务发现业务，因此我们在设定端口为0之后,我们可以通过getsockname函数获取当前的句柄bind的端口，下面给定一个简单的linux例子: 123456789101112131415struct sockaddr_in serveraddr;socklen_t len = sizeof(serveraddr);int bindPort;if (bind(sockfd, (sockaddr *)&amp;serveraddr, sizeof(serveraddr)) == -1){ // Warning(&quot;%s, Failed to bind server socket at address[%s:%s]\\n&quot;, __PRETTY_FUNCTION__, ip.data(), port.data()); close(sockfd); return false;}getsockname(sockfd, (struct sockaddr *) &amp;serveraddr, &amp;len);bindPort = ntohs(serveraddr.sin_port); // get the real port 参考资料 Linux Bind doc Linux Ip doc Linux how to change port range Windows Bind doc","link":"/2022/01/12/%E7%9B%91%E5%90%AC%E9%9A%8F%E6%9C%BA%E7%AB%AF%E5%8F%A3/"}],"tags":[{"name":"profile","slug":"profile","link":"/tags/profile/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"shell","slug":"shell","link":"/tags/shell/"},{"name":"lua","slug":"lua","link":"/tags/lua/"},{"name":"cpp","slug":"cpp","link":"/tags/cpp/"},{"name":"c","slug":"c","link":"/tags/c/"},{"name":"database","slug":"database","link":"/tags/database/"},{"name":"C#","slug":"C","link":"/tags/C/"},{"name":"NSIS","slug":"NSIS","link":"/tags/NSIS/"},{"name":"windows","slug":"windows","link":"/tags/windows/"},{"name":"ssl","slug":"ssl","link":"/tags/ssl/"},{"name":"VPN","slug":"VPN","link":"/tags/VPN/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"blog","slug":"blog","link":"/tags/blog/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"game","slug":"game","link":"/tags/game/"},{"name":"theory","slug":"theory","link":"/tags/theory/"},{"name":"network","slug":"network","link":"/tags/network/"},{"name":"socket","slug":"socket","link":"/tags/socket/"}],"categories":[{"name":"Tools","slug":"Tools","link":"/categories/Tools/"},{"name":"Code","slug":"Code","link":"/categories/Code/"},{"name":"Theory","slug":"Theory","link":"/categories/Theory/"}],"pages":[{"title":"About","text":"","link":"/about/index.html"},{"title":"Tags","text":"","link":"/tags/index.html"}]}